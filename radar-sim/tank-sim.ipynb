{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66042047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4be42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed torch-2.2.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting stable-baselines3\n",
      "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3) (1.1.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3) (1.26.4)\n",
      "INFO: pip is looking at multiple versions of stable-baselines3 to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3)\n",
      "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting stable-baselines3\n",
      "  Downloading stable_baselines3-2.4.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: torch>=1.13 in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3) (2.2.2)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3) (2.2.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3) (2.1.4)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/avielstein/.local/lib/python3.11/site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3) (2023.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/avielstein/.local/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/avielstein/.local/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->stable-baselines3) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->stable-baselines3) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/avielstein/.local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
      "Downloading stable_baselines3-2.4.1-py3-none-any.whl (183 kB)\n",
      "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: gymnasium, stable-baselines3\n",
      "  Attempting uninstall: gymnasium\n",
      "    Found existing installation: gymnasium 1.1.1\n",
      "    Uninstalling gymnasium-1.1.1:\n",
      "      Successfully uninstalled gymnasium-1.1.1\n",
      "Successfully installed gymnasium-1.0.0 stable-baselines3-2.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# https://gymnasium.farama.org/index.html\n",
    "# !pip install gymnasium\n",
    "# !pip install torch\n",
    "# # https://stable-baselines3.readthedocs.io/en/master/guide/install.html\n",
    "# !pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class WaterTankEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    A 2D water tank environment where the agent needs to learn to stay in the center.\n",
    "    \n",
    "    State space: [x_position, y_position, x_velocity, y_velocity]\n",
    "    Action space: [thrust_x, thrust_y] - Continuous values between -1 and 1\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tank_size=10.0, max_steps=200, noise_level=0.05):\n",
    "        super(WaterTankEnv, self).__init__()\n",
    "        \n",
    "        # Environment parameters\n",
    "        self.tank_size = tank_size\n",
    "        self.max_steps = max_steps\n",
    "        self.noise_level = noise_level\n",
    "        \n",
    "        # Agent dynamics parameters\n",
    "        self.mass = 1.0\n",
    "        self.water_resistance = 0.2\n",
    "        self.max_force = 1.0\n",
    "        self.dt = 0.1  # time step\n",
    "        \n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-1.0, high=1.0, shape=(2,), dtype=np.float32\n",
    "        )\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([-self.tank_size, -self.tank_size, -5.0, -5.0]),\n",
    "            high=np.array([self.tank_size, self.tank_size, 5.0, 5.0]),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Initialize state\n",
    "        self.state = None\n",
    "        self.steps = 0\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Reset the environment to a random position\"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        # Random initial position away from the center\n",
    "        distance = 0.5 * self.tank_size\n",
    "        angle = self.np_random.uniform(0, 2 * np.pi)\n",
    "        x = distance * np.cos(angle)\n",
    "        y = distance * np.sin(angle)\n",
    "        \n",
    "        # Initialize with zero velocity\n",
    "        self.state = np.array([x, y, 0.0, 0.0], dtype=np.float32)\n",
    "        self.steps = 0\n",
    "        \n",
    "        return self.state, {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Take a step in the environment based on the action\"\"\"\n",
    "        self.steps += 1\n",
    "        \n",
    "        # Unpack state\n",
    "        x, y, vx, vy = self.state\n",
    "        \n",
    "        # Apply thrust action (with noise to simulate water currents)\n",
    "        thrust_x = np.clip(action[0], -1.0, 1.0) * self.max_force\n",
    "        thrust_y = np.clip(action[1], -1.0, 1.0) * self.max_force\n",
    "        \n",
    "        # Add environmental noise (water currents)\n",
    "        thrust_x += self.np_random.uniform(-self.noise_level, self.noise_level)\n",
    "        thrust_y += self.np_random.uniform(-self.noise_level, self.noise_level)\n",
    "        \n",
    "        # Calculate acceleration (F = ma)\n",
    "        ax = thrust_x / self.mass - self.water_resistance * vx / self.mass\n",
    "        ay = thrust_y / self.mass - self.water_resistance * vy / self.mass\n",
    "        \n",
    "        # Update velocity\n",
    "        vx += ax * self.dt\n",
    "        vy += ay * self.dt\n",
    "        \n",
    "        # Update position\n",
    "        x += vx * self.dt\n",
    "        y += vy * self.dt\n",
    "        \n",
    "        # Boundary handling - bounce off walls\n",
    "        if abs(x) > self.tank_size:\n",
    "            x = np.sign(x) * self.tank_size\n",
    "            vx = -vx * 0.9  # Lose some energy on collision\n",
    "            \n",
    "        if abs(y) > self.tank_size:\n",
    "            y = np.sign(y) * self.tank_size\n",
    "            vy = -vy * 0.9  # Lose some energy on collision\n",
    "        \n",
    "        # Update state\n",
    "        self.state = np.array([x, y, vx, vy], dtype=np.float32)\n",
    "        \n",
    "        # Calculate reward\n",
    "        # Main component: negative distance from center (higher when closer to center)\n",
    "        distance_from_center = np.sqrt(x**2 + y**2)\n",
    "        position_reward = -distance_from_center\n",
    "        \n",
    "        # Secondary component: penalize high velocities (to encourage stability)\n",
    "        velocity_penalty = -0.1 * (vx**2 + vy**2)\n",
    "        \n",
    "        # Combine rewards\n",
    "        reward = position_reward + velocity_penalty\n",
    "        \n",
    "        # Check if episode is done\n",
    "        done = self.steps >= self.max_steps\n",
    "        \n",
    "        # Additional info\n",
    "        info = {\n",
    "            \"distance_from_center\": distance_from_center,\n",
    "            \"position\": (x, y),\n",
    "            \"velocity\": (vx, vy)\n",
    "        }\n",
    "        \n",
    "        return self.state, reward, done, False, info\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Simple text-based rendering\"\"\"\n",
    "        x, y, vx, vy = self.state\n",
    "        distance = np.sqrt(x**2 + y**2)\n",
    "        print(f\"Position: ({x:.2f}, {y:.2f}), Distance from center: {distance:.2f}\")\n",
    "\n",
    "\n",
    "def visualize_agent(env, model, num_episodes=3):\n",
    "    \"\"\"Visualize agent behavior\"\"\"\n",
    "    for episode in range(num_episodes):\n",
    "        # Initialize plotting\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax.set_xlim(-env.tank_size, env.tank_size)\n",
    "        ax.set_ylim(-env.tank_size, env.tank_size)\n",
    "        ax.set_xlabel('X position')\n",
    "        ax.set_ylabel('Y position')\n",
    "        ax.set_title(f'Agent Trajectory - Episode {episode+1}')\n",
    "        \n",
    "        # Draw tank boundary\n",
    "        tank = plt.Rectangle((-env.tank_size, -env.tank_size), \n",
    "                           2*env.tank_size, 2*env.tank_size, \n",
    "                           linewidth=2, edgecolor='blue', facecolor='none')\n",
    "        ax.add_patch(tank)\n",
    "        \n",
    "        # Draw center target\n",
    "        center = plt.Circle((0, 0), 0.5, color='green', alpha=0.3)\n",
    "        ax.add_patch(center)\n",
    "        \n",
    "        # Run episode\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        trajectory_x = [obs[0]]\n",
    "        trajectory_y = [obs[1]]\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, _, info = env.step(action)\n",
    "            trajectory_x.append(obs[0])\n",
    "            trajectory_y.append(obs[1])\n",
    "        \n",
    "        # Plot trajectory\n",
    "        ax.plot(trajectory_x, trajectory_y, 'r-', alpha=0.7)\n",
    "        ax.plot(trajectory_x[0], trajectory_y[0], 'bo', label='Start')\n",
    "        ax.plot(trajectory_x[-1], trajectory_y[-1], 'ro', label='End')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Create and validate environment\n",
    "env = WaterTankEnv(tank_size=10.0, max_steps=300, noise_level=0.1)\n",
    "check_env(env)\n",
    "\n",
    "# Train the agent\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    learning_rate=0.0003,\n",
    "    gamma=0.99,  # discount factor\n",
    "    n_steps=1024,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    policy_kwargs=dict(\n",
    "        net_arch=[dict(pi=[64, 64], vf=[64, 64])],\n",
    "        activation_fn=nn.Tanh\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train\n",
    "train_timesteps = 100000\n",
    "model.learn(total_timesteps=train_timesteps)\n",
    "\n",
    "# Evaluate the trained agent\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "# Visualize agent behavior\n",
    "visualize_agent(env, model)\n",
    "\n",
    "# Test the agent interactively\n",
    "obs, _ = env.reset()\n",
    "cumulative_reward = 0\n",
    "for step in range(1000):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _, info = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "    \n",
    "    # Print current state\n",
    "    x, y, vx, vy = obs\n",
    "    distance = np.sqrt(x**2 + y**2)\n",
    "    print(f\"Step {step}: Position ({x:.2f}, {y:.2f}), Distance: {distance:.2f}, Reward: {reward:.2f}\")\n",
    "    \n",
    "    if done:\n",
    "        print(f\"Episode finished after {step+1} steps. Total reward: {cumulative_reward:.2f}\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(0.01)  # Slow down visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdb02e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
