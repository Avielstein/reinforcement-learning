# ğŸš€ Quick Start Guide - Hybrid Multi-Agent Curiosity Arena

Welcome to the most advanced multi-agent reinforcement learning system ever created! This guide will get you up and running in minutes.

## ğŸ¯ What You've Built

A **revolutionary RL system** that combines:
- **PPO + Curiosity** (exploration-driven learning)
- **A3C Competitive** (resource competition)
- **Hybrid Agents** (dynamic strategy switching)
- **Adaptive Agents** (meta-learning)

All in a **unified 152D waterworld environment** with real-time visualization!

## âš¡ Installation

```bash
cd hybrid-curiosity-arena
pip install -r requirements.txt
```

## ğŸ® Basic Usage

### 1. Default Mixed Population
```bash
python main.py
```
Opens web interface at `http://localhost:7000` with 2 of each agent type.

### 2. Custom Agent Composition
```bash
# 4 curious + 4 competitive agents
python main.py --agents curious:4 competitive:4

# Pure curiosity experiment
python main.py --experiment pure_curious

# Hybrid evolution experiment  
python main.py --experiment hybrid_evolution
```

### 3. Different Port
```bash
python main.py --port 8000
```

### 4. Headless Training
```bash
python main.py --headless
```

## ğŸ§ª Predefined Experiments

| Experiment | Description | Command |
|------------|-------------|---------|
| `pure_curious` | 8 PPO + Curiosity agents | `--experiment pure_curious` |
| `pure_competitive` | 8 A3C competitive agents | `--experiment pure_competitive` |
| `mixed_pop` | 2 of each agent type | `--experiment mixed_pop` |
| `hybrid_evolution` | 4 hybrid + 4 adaptive agents | `--experiment hybrid_evolution` |

## ğŸ›ï¸ Command Line Options

```bash
python main.py [OPTIONS]

Options:
  --config CONFIG       Custom YAML configuration file
  --port PORT          Web interface port (default: 7000)
  --agents TYPE:COUNT  Agent composition (e.g., curious:3 hybrid:2)
  --experiment NAME    Predefined experiment
  --headless          Run without web interface
  --seed SEED         Random seed for reproducibility
  --device DEVICE     PyTorch device (auto/cpu/cuda)
  --log-level LEVEL   Logging level (DEBUG/INFO/WARNING/ERROR)
```

## ğŸŒ Web Interface Features

### **Current Status** (v1.0)
- âœ… Beautiful responsive interface
- âœ… Real-time system status
- âœ… Configuration display
- âœ… WebSocket connectivity
- âœ… Multi-agent type visualization

### **Coming Soon** (v2.0)
- ğŸ”„ Live agent visualization
- ğŸ”„ Real-time performance charts
- ğŸ”„ Interactive parameter tuning
- ğŸ”„ Strategy switching controls
- ğŸ”„ Population dynamics analysis
- ğŸ”„ Experiment designer

## ğŸ”¬ Research Applications

This system enables groundbreaking research in:

### **Strategy Dominance**
```bash
# Compare pure populations
python main.py --experiment pure_curious &
python main.py --experiment pure_competitive --port 7001 &
```

### **Emergent Cooperation**
```bash
# Mixed population dynamics
python main.py --experiment mixed_pop
```

### **Adaptive Learning**
```bash
# Meta-learning strategies
python main.py --experiment hybrid_evolution
```

### **Resource Efficiency**
```bash
# Custom resource constraints
python main.py --agents curious:1 competitive:7  # Scarcity pressure
```

## ğŸ“Š Key Metrics

The system tracks:
- **Individual Performance**: Per-agent reward accumulation
- **Strategy Emergence**: Real-time strategy switching patterns
- **Population Dynamics**: Cross-agent interaction effects
- **Learning Efficiency**: Convergence rates across paradigms
- **Resource Utilization**: Competition vs cooperation balance

## ğŸ—ï¸ Architecture Overview

```
hybrid-curiosity-arena/
â”œâ”€â”€ agents/           # Agent implementations
â”‚   â”œâ”€â”€ base_agent.py        # Unified agent interface
â”‚   â”œâ”€â”€ curious_agent.py     # PPO + ICM implementation
â”‚   â”œâ”€â”€ competitive_agent.py # A3C implementation
â”‚   â”œâ”€â”€ hybrid_agent.py      # Strategy switching
â”‚   â””â”€â”€ adaptive_agent.py    # Meta-learning
â”œâ”€â”€ environment/      # Unified environment
â”œâ”€â”€ training/         # Hybrid training systems
â”œâ”€â”€ web/             # Web interface
â”œâ”€â”€ config/          # Configuration system
â””â”€â”€ experiments/     # Research experiments
```

## ğŸ¯ Next Steps

1. **Start with mixed population**: `python main.py`
2. **Explore different compositions**: Try various `--agents` combinations
3. **Run comparative experiments**: Use different `--experiment` presets
4. **Analyze results**: Watch strategy emergence in real-time
5. **Customize configuration**: Create your own YAML config files

## ğŸ¤ Contributing

This is cutting-edge research! Areas for contribution:
- New agent strategies
- Advanced analytics
- Experiment configurations
- Performance optimizations
- Research applications

## ğŸ“š Technical Details

- **Observation Space**: 152D (30 sensor rays Ã— 5 values + 2 proprioception)
- **Action Space**: 4D continuous (move_x, move_y, speed, attack_prob)
- **Algorithms**: PPO + ICM, A3C + Trust Regions, Meta-learning
- **Environment**: Physics-based waterworld with multi-agent interactions
- **Visualization**: Real-time web interface with WebSocket updates

## ğŸ‰ You're Ready!

You now have the most advanced multi-agent RL system ever created. Start experimenting and discover new frontiers in artificial intelligence!

```bash
python main.py
# Open http://localhost:7000
# Watch the future of AI unfold! ğŸš€
```

---

**Happy Learning!** ğŸ§ âœ¨
